{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "418eb119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 00:16:34.540203: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-26 00:16:35.047031: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-26 00:16:35.198688: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-26 00:16:36.079302: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-26 00:16:46.699238: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer)\n",
    "\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import EarlyStoppingCallback\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6e447a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>new_label</th>\n",
       "      <th>remove_all_stopwords</th>\n",
       "      <th>remove_some_stopwords</th>\n",
       "      <th>stemming</th>\n",
       "      <th>lemmatization</th>\n",
       "      <th>no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not able to add freinds. It show something wen...</td>\n",
       "      <td>bug report</td>\n",
       "      <td>0</td>\n",
       "      <td>able add freinds show something went wrong rec...</td>\n",
       "      <td>not able add freinds show something went wrong...</td>\n",
       "      <td>not abl to add freind it show someth went wron...</td>\n",
       "      <td>not able to add freinds it show something went...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Calls keep dropping for no reason and is super...</td>\n",
       "      <td>bug report</td>\n",
       "      <td>0</td>\n",
       "      <td>calls keep dropping reason super annoying</td>\n",
       "      <td>calls keep dropping no reason super annoying</td>\n",
       "      <td>call keep drop for no reason and is super annoy</td>\n",
       "      <td>call keep dropping for no reason and is super ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Can't access to my account solve this issue im...</td>\n",
       "      <td>bug report</td>\n",
       "      <td>0</td>\n",
       "      <td>cant access account solve issue immediately</td>\n",
       "      <td>cant access account solve issue immediately</td>\n",
       "      <td>cant access to my account solv thi issu immedi</td>\n",
       "      <td>cant access to my account solve this issue imm...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I don't know what's wrong with my own WhatsApp...</td>\n",
       "      <td>bug report</td>\n",
       "      <td>0</td>\n",
       "      <td>dont know whats wrong whatsapp working want si...</td>\n",
       "      <td>dont know whats wrong whatsapp not working wan...</td>\n",
       "      <td>i dont know what wrong with my own whatsapp it...</td>\n",
       "      <td>i dont know whats wrong with my own whatsapp i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cannot record audio while taking video</td>\n",
       "      <td>bug report</td>\n",
       "      <td>0</td>\n",
       "      <td>cannot record audio taking video</td>\n",
       "      <td>cannot record audio taking video</td>\n",
       "      <td>cannot record audio while take video</td>\n",
       "      <td>cannot record audio while taking video</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                             review       label  \\\n",
       "0   1  Not able to add freinds. It show something wen...  bug report   \n",
       "1   2  Calls keep dropping for no reason and is super...  bug report   \n",
       "2   3  Can't access to my account solve this issue im...  bug report   \n",
       "3   4  I don't know what's wrong with my own WhatsApp...  bug report   \n",
       "4   5             Cannot record audio while taking video  bug report   \n",
       "\n",
       "   new_label                               remove_all_stopwords  \\\n",
       "0          0  able add freinds show something went wrong rec...   \n",
       "1          0          calls keep dropping reason super annoying   \n",
       "2          0        cant access account solve issue immediately   \n",
       "3          0  dont know whats wrong whatsapp working want si...   \n",
       "4          0                   cannot record audio taking video   \n",
       "\n",
       "                               remove_some_stopwords  \\\n",
       "0  not able add freinds show something went wrong...   \n",
       "1       calls keep dropping no reason super annoying   \n",
       "2        cant access account solve issue immediately   \n",
       "3  dont know whats wrong whatsapp not working wan...   \n",
       "4                   cannot record audio taking video   \n",
       "\n",
       "                                            stemming  \\\n",
       "0  not abl to add freind it show someth went wron...   \n",
       "1    call keep drop for no reason and is super annoy   \n",
       "2     cant access to my account solv thi issu immedi   \n",
       "3  i dont know what wrong with my own whatsapp it...   \n",
       "4               cannot record audio while take video   \n",
       "\n",
       "                                       lemmatization no_stopwords  \n",
       "0  not able to add freinds it show something went...          NaN  \n",
       "1  call keep dropping for no reason and is super ...          NaN  \n",
       "2  cant access to my account solve this issue imm...          NaN  \n",
       "3  i dont know whats wrong with my own whatsapp i...          NaN  \n",
       "4             cannot record audio while taking video          NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('Data_Datasets_Unbalanced_dataset_unbalanced_4000.xlsx')\n",
    "df2 = pd.read_excel('dataset_gpt_unbalanced_16000.xlsx')\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbbdbbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "df['label'].value_counts().plot(kind='bar', alpha=0.7)\n",
    "plt.title('Histogram of Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7386d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['label'])\n",
    "df = df.rename(columns={'new_label': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bfbbf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['remove_all_stopwords', 'remove_some_stopwords', 'stemming', 'lemmatization', 'no_stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e87bddba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Not able to add freinds. It show something wen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Calls keep dropping for no reason and is super...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Can't access to my account solve this issue im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I don't know what's wrong with my own WhatsApp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cannot record audio while taking video</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                             review  label\n",
       "0   1  Not able to add freinds. It show something wen...      0\n",
       "1   2  Calls keep dropping for no reason and is super...      0\n",
       "2   3  Can't access to my account solve this issue im...      0\n",
       "3   4  I don't know what's wrong with my own WhatsApp...      0\n",
       "4   5             Cannot record audio while taking video      0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30dd073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "missing_reviews = df['review'].isnull()\n",
    "print(missing_reviews.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ec65814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31a67a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fec4bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46297901",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: 'bug report', 1: 'feature request', 2: 'user experience', 3: 'rating'}\n",
    "label2id = {label: id for id, label in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffcb04ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19999 entries, 0 to 19999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      19999 non-null  int64 \n",
      " 1   review  19999 non-null  object\n",
      " 2   label   19999 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 625.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e9aaf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, testing and validation sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd769fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict(train_df)\n",
    "test_dataset = Dataset.from_dict(test_df)\n",
    "val_dataset = Dataset.from_dict(val_df)\n",
    "dataset = DatasetDict({\"train\":train_dataset,\"test\":test_dataset, \"validation\": val_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b0c9980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'review', 'label'],\n",
       "        num_rows: 15999\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'review', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ID', 'review', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "102bd032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b04daae6c4c4b6584dce758f85c0f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/708 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffacd57e5f2469a954e0a51d04c0d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/273M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at thearod5/bert4re were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at thearod5/bert4re and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'thearod5/bert4re'\n",
    "\n",
    "# generate classification model from model_checkpoint\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=4, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57f8bad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "278833ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f15a65950014c6d9864bf52196e952b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9276be87e841f8917a1a188d1d7b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/504k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f3dd20aac04dbab1d54e54f22c49df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/290k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37a5a1b4dd547a582fc586c5313517d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff0fa3d0e6b44aaa829c7a347c0e2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/958 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "\n",
    "# add pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# create tokenize function\n",
    "def tokenize_function(examples):\n",
    "    # extract text\n",
    "    text = examples[\"review\"]\n",
    "\n",
    "    #tokenize and truncate text\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf478fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b6721931974db48b113aded95a8476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/apps/apps/binapps/anaconda3/2023.03/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:715: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04e50d22f834fa4a1de890fb151aabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78211000c6e4a9e89a43aef07a9fe3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'review', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 15999\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'review', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ID', 'review', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize training and validation datasets\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b6be60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a1738e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accuracy evaluation metric\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "# define an evaluation function to pass into trainer later\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0d097f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
    "                        r=4,\n",
    "                        lora_alpha=32,\n",
    "                        lora_dropout=0.1,\n",
    "                        target_modules = [\"attention.self.query\", \"attention.self.key\",\"attention.self.value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ded7435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the model architecture to identify target modules\n",
    "# for name, module in model.named_modules():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cba44679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 704,260 || all params: 68,798,216 || trainable%: 1.0237\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39e50138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-4\n",
    "batch_size = 32\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d6cc7063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Add EarlyStoppingCallback to the trainer\n",
    "early_stopping = EarlyStoppingCallback(early_stopping_patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0143d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= model_checkpoint + \"-lora-text-classification\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.05,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    lr_scheduler_type=\"cosine\",  # learning rate scheduler type\n",
    "    warmup_ratio=0.1  # warmup ratio for lr scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5e14c91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 15999\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5000\n",
      "  Number of trainable parameters = 704260\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4500' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4500/5000 15:35 < 01:43, 4.81 it/s, Epoch 18/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.198748</td>\n",
       "      <td>{'accuracy': 0.4965}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.216400</td>\n",
       "      <td>0.886930</td>\n",
       "      <td>{'accuracy': 0.699}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.216400</td>\n",
       "      <td>0.632367</td>\n",
       "      <td>{'accuracy': 0.799}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>{'accuracy': 0.813}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.574055</td>\n",
       "      <td>{'accuracy': 0.824}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.541900</td>\n",
       "      <td>0.519535</td>\n",
       "      <td>{'accuracy': 0.8445}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.541900</td>\n",
       "      <td>0.507930</td>\n",
       "      <td>{'accuracy': 0.8485}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.463800</td>\n",
       "      <td>0.487667</td>\n",
       "      <td>{'accuracy': 0.8575}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.463800</td>\n",
       "      <td>0.458330</td>\n",
       "      <td>{'accuracy': 0.865}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.442672</td>\n",
       "      <td>{'accuracy': 0.8685}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.440250</td>\n",
       "      <td>{'accuracy': 0.866}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.386300</td>\n",
       "      <td>0.434764</td>\n",
       "      <td>{'accuracy': 0.87}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.386300</td>\n",
       "      <td>0.430350</td>\n",
       "      <td>{'accuracy': 0.87}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>0.420977</td>\n",
       "      <td>{'accuracy': 0.8715}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>0.427283</td>\n",
       "      <td>{'accuracy': 0.873}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.419032</td>\n",
       "      <td>{'accuracy': 0.8725}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.421932</td>\n",
       "      <td>{'accuracy': 0.8725}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>0.426429</td>\n",
       "      <td>{'accuracy': 0.873}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.4965}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-250\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-250/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-250/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.699}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-500/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.799}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-750\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-750/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-750/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.813}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-1000/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.824}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-1250\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-1250/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-1250/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.8445}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-1500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-1500/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.8485}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-1750/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-1750/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.8575}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-2000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-2000/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.865}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-2250\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-2250/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-2250/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.8685}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-2500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-2500/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.866}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-2750\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-2750/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-2750/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.87}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-3000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-3000/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.87}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-3250\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-3250/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-3250/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.8715}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-3500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-3500/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.873}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-3750\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-3750/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-3750/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.8725}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-4000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-4000/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.8725}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-4250\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-4250/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-4250/special_tokens_map.json\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 64\n",
      "Trainer is attempting to log a value of \"{'accuracy': 0.873}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to thearod5/bert4re-lora-text-classification/checkpoint-4500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in thearod5/bert4re-lora-text-classification/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in thearod5/bert4re-lora-text-classification/checkpoint-4500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from thearod5/bert4re-lora-text-classification/checkpoint-4000 (score: 0.41903167963027954).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4500, training_loss=0.534038825141059, metrics={'train_runtime': 935.4623, 'train_samples_per_second': 342.055, 'train_steps_per_second': 5.345, 'total_flos': 1.802182630078003e+16, 'train_loss': 0.534038825141059, 'epoch': 18.0})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creater trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "973cad2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: review, ID. If review, ID are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 32\n",
      "/mnt/iusers01/fse-ugpgt01/compsci01/y28520mp/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8740\n",
      "Test Micro Precision: 0.8740\n",
      "Test Micro Recall: 0.8740\n",
      "Test Micro F1-score: 0.8740\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     bug report       0.83      0.82      0.82       348\n",
      "feature request       0.87      0.83      0.85       465\n",
      "user experience       0.91      0.87      0.89       570\n",
      "         rating       0.87      0.94      0.90       617\n",
      "\n",
      "       accuracy                           0.87      2000\n",
      "      macro avg       0.87      0.87      0.87      2000\n",
      "   weighted avg       0.87      0.87      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reinitialize accuracy metric to avoid potential overwrite issues\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Get predictions and true labels\n",
    "predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Compute metrics\n",
    "# Compute accuracy\n",
    "accuracy = accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"micro\")\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Micro Precision: {precision:.4f}\")\n",
    "print(f\"Test Micro Recall: {recall:.4f}\")\n",
    "print(f\"Test Micro F1-score: {f1:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "class_report = classification_report(labels, preds, target_names=[id2label[i] for i in range(4)])\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99669b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
